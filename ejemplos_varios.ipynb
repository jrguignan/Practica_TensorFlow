{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo Funcion Lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = tf.convert_to_tensor(np.array([2,4,6,8,10,12]), dtype='float32')\n",
    "\n",
    "b_const = tf.constant([2.0])\n",
    "\n",
    "m_const = tf.constant(3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediccion \n",
    "\n",
    "$$Y = mx + b$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([ 8. 14. 20. 26. 32. 38.], shape=(6,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "y_data = tf.add(tf.multiply(m_const,X_val),b_const)\n",
    "\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ejemplo Red Neuronal Convolucional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_data = tf.convert_to_tensor(np.random.rand(1,4,4,1), dtype='float32')\n",
    "\n",
    "filtro = tf.constant(0.25, shape=[2,2,1,1])\n",
    "\n",
    "strides = [1,2,2,1]\n",
    "\n",
    "mov_avg_layer = tf.nn.conv2d(X_data, filtro, strides,padding='SAME', name ='Moving_avg_windows'  )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dimension de salida:\n",
    "\n",
    "$$\\frac{dim entrada - dim filtro + 2 padding}{stride} + 1 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función tf.nn.conv2d() en TensorFlow realiza una operación de convolución 2D sobre una entrada. Aquí tienes una explicación detallada de sus principales parámetros:\n",
    "\n",
    "input:\n",
    "Descripción: Este es el tensor de entrada sobre el cual se realizará la convolución.\n",
    "Forma: El tensor debe tener una forma [batch, height, width, channels], donde:\n",
    "batch es el número de imágenes en el lote.\n",
    "height es la altura de la imagen.\n",
    "width es el ancho de la imagen.\n",
    "channels es el número de canales de la imagen (por ejemplo, 3 para imágenes RGB).\n",
    "\n",
    "filters (también llamado weights o kernel):\n",
    "Descripción: Este es el tensor que contiene los filtros (o kernels) utilizados para la convolución.\n",
    "Forma: El tensor de filtros debe tener una forma [filter_height, filter_width, in_channels, out_channels], donde:\n",
    "filter_height es la altura del filtro.\n",
    "filter_width es el ancho del filtro.\n",
    "in_channels es el número de canales de entrada (igual al número de canales de la entrada).\n",
    "out_channels es el número de filtros o mapas de características (es decir, el número de canales de salida).\n",
    "\n",
    "strides:\n",
    "Descripción: Este parámetro especifica el paso de la convolución a lo largo de cada dimensión de la entrada.\n",
    "Forma: Es una lista de cuatro valores [1, stride_height, stride_width, 1].\n",
    "1 es el paso en la dimensión del lote (se mantiene como 1).\n",
    "stride_height es el paso a lo largo de la altura de la imagen.\n",
    "stride_width es el paso a lo largo del ancho de la imagen.\n",
    "1 es el paso en la dimensión del canal (se mantiene como 1).\n",
    "\n",
    "padding:\n",
    "Descripción: Este parámetro especifica el tipo de relleno a aplicar a la entrada.\n",
    "Valores posibles:\n",
    "'SAME': Aplica un relleno de manera que la salida tenga la misma dimensión espacial que la entrada.\n",
    "'VALID': No aplica relleno, por lo que la dimensión espacial de la salida se reduce."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Capa a medida, reduce las dimesiones, realiza unas multiplicaciones de matrices\n",
    "#y aplica una funcion sidmoide\n",
    "\n",
    "def custom_layer(input_matrix):\n",
    "    input_matrix_squeezed = tf.squeeze(input_matrix)\n",
    "    A = tf.constant([[1.,2.],[3.,4]])\n",
    "    b = tf.constant(1., shape = [2,2])\n",
    "    temp1 = tf.matmul(A, input_matrix_squeezed)\n",
    "    temp2 = tf.add(temp1, b) ## Ax+b\n",
    "    return tf.sigmoid(temp2)\n",
    "\n",
    "#aplica la funcion a la capa\n",
    "with tf.name_scope('Custom_Layer') as scope:\n",
    "    customlayer1 = custom_layer(mov_avg_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.942152   0.93658537]\n",
      " [0.99312407 0.99367476]], shape=(2, 2), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#capa de salida\n",
    "print(customlayer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[[[0.39213204]\n",
      "   [0.67176855]]\n",
      "\n",
      "  [[0.69910824]\n",
      "   [0.51038855]]]], shape=(1, 2, 2, 1), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#Salida de la convolucion\n",
    "print(mov_avg_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ejemplo de codigo para usar tensorboar con una RNA\n",
    "\n",
    "#grafica la presicion a lo largo de las epocas\n",
    "\n",
    "mnist = tf.keras.datasets.mnist\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "def create_model():\n",
    "  return tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10, activation='softmax')\n",
    "  ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jrgui\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 11ms/step - accuracy: 0.8915 - loss: 0.3644 - val_accuracy: 0.9683 - val_loss: 0.1006\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 10ms/step - accuracy: 0.9699 - loss: 0.1000 - val_accuracy: 0.9696 - val_loss: 0.0966\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 10ms/step - accuracy: 0.9783 - loss: 0.0692 - val_accuracy: 0.9755 - val_loss: 0.0723\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.9848 - loss: 0.0513 - val_accuracy: 0.9758 - val_loss: 0.0816\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 10ms/step - accuracy: 0.9875 - loss: 0.0396 - val_accuracy: 0.9775 - val_loss: 0.0749\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x12c6daef690>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "model.fit(x=x_train, \n",
    "          y=y_train, \n",
    "          epochs=5, \n",
    "          validation_data=(x_test, y_test), \n",
    "          callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para poder ver las gráficas:\n",
    "\n",
    "Se debe correr en la shell(terminal) \n",
    ">tensorboard --logdir tensorboard/\n",
    "\n",
    "Luego colocar lo siguiente dentro de un navegador:\n",
    "http://localhost:6006/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
